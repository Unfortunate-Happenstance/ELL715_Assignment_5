{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Training for Viola-Jones Face Detector\n",
    "\n",
    "Train AdaBoost classifier on face patches using Haar features.\n",
    "\n",
    "**V1 Configuration**:\n",
    "- Features: 10,000 Haar features\n",
    "- Rounds: T=50\n",
    "- Dataset: 799 face + 3,995 non-face patches\n",
    "\n",
    "**AI Usage**: Notebook structure assisted by Claude Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from features.integral_image import compute_ii_fast\n",
    "from features.haar_features import generate_haar_features, compute_feature_responses\n",
    "from classifiers.adaboost import train_adaboost, evaluate_classifier\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Training: 799 faces, 3995 non-faces\n",
      "Testing: 2260 faces, 11300 non-faces\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "\n",
    "# Load training data\n",
    "with open('../data/processed/train_faces.pkl', 'rb') as f:\n",
    "    train_faces = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/train_nonfaces.pkl', 'rb') as f:\n",
    "    train_nonfaces = pickle.load(f)\n",
    "\n",
    "# Load testing data\n",
    "with open('../data/processed/test_faces.pkl', 'rb') as f:\n",
    "    test_faces = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/test_nonfaces.pkl', 'rb') as f:\n",
    "    test_nonfaces = pickle.load(f)\n",
    "\n",
    "print(f\"Training: {len(train_faces)} faces, {len(train_nonfaces)} non-faces\")\n",
    "print(f\"Testing: {len(test_faces)} faces, {len(test_nonfaces)} non-faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Training Data\n",
    "\n",
    "Combine faces and non-faces into single arrays with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: 4794 samples\n",
      "  Positive (faces): 799\n",
      "  Negative (non-faces): 3995\n",
      "\n",
      "Test set: 13560 samples\n",
      "  Positive (faces): 2260\n",
      "  Negative (non-faces): 11300\n"
     ]
    }
   ],
   "source": [
    "# Combine training data\n",
    "X_train = np.concatenate([train_faces, train_nonfaces], axis=0)\n",
    "y_train = np.concatenate([\n",
    "    np.ones(len(train_faces), dtype=int),   # faces = 1\n",
    "    np.zeros(len(train_nonfaces), dtype=int)  # non-faces = 0\n",
    "])\n",
    "\n",
    "# Combine testing data\n",
    "X_test = np.concatenate([test_faces, test_nonfaces], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    np.ones(len(test_faces), dtype=int),\n",
    "    np.zeros(len(test_nonfaces), dtype=int)\n",
    "])\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"  Positive (faces): {np.sum(y_train == 1)}\")\n",
    "print(f\"  Negative (non-faces): {np.sum(y_train == 0)}\")\n",
    "print(f\"\\nTest set: {X_test.shape[0]} samples\")\n",
    "print(f\"  Positive (faces): {np.sum(y_test == 1)}\")\n",
    "print(f\"  Negative (non-faces): {np.sum(y_test == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Haar Features\n",
    "\n",
    "Generate 10,000 features for V1 (simplified version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Haar features...\n",
      "Generating Haar features for 16Ã—16 window...\n",
      "  Generating 2-rectangle horizontal features...\n",
      "  Generating 2-rectangle vertical features...\n",
      "\n",
      "Generated 10000 Haar features\n",
      "\n",
      "First 5 features:\n",
      "  1. HaarFeature(type=2h, pos=(0,0), size=1x2)\n",
      "  2. HaarFeature(type=2h, pos=(0,0), size=1x4)\n",
      "  3. HaarFeature(type=2h, pos=(0,0), size=1x6)\n",
      "  4. HaarFeature(type=2h, pos=(0,0), size=1x8)\n",
      "  5. HaarFeature(type=2h, pos=(0,0), size=1x10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating Haar features...\")\n",
    "features = generate_haar_features(window_size=16, max_features=10000)\n",
    "print(f\"\\nGenerated {len(features)} Haar features\")\n",
    "\n",
    "# Show first few features\n",
    "print(\"\\nFirst 5 features:\")\n",
    "for i, feat in enumerate(features[:5]):\n",
    "    print(f\"  {i+1}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Feature Response Matrix\n",
    "\n",
    "**This is computationally expensive!**\n",
    "- Training: 4,794 patches x 10,000 features = 47.9M evaluations\n",
    "- Testing: 13,560 patches x 10,000 features = 135.6M evaluations\n",
    "\n",
    "Pre-computing and saving for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed training responses...\n",
      "\n",
      "Training response matrix: (4794, 10000)\n",
      "  Memory: 191.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Check if already computed\n",
    "train_response_file = Path('../data/processed/train_responses_10k.npy')\n",
    "test_response_file = Path('../data/processed/test_responses_10k.npy')\n",
    "\n",
    "if train_response_file.exists():\n",
    "    print(\"Loading pre-computed training responses...\")\n",
    "    train_responses = np.load(train_response_file)\n",
    "else:\n",
    "    print(\"Computing training feature responses...\")\n",
    "    print(\"This may take several minutes...\")\n",
    "    train_responses = compute_feature_responses(features, X_train)\n",
    "    np.save(train_response_file, train_responses)\n",
    "    print(f\"Saved to {train_response_file}\")\n",
    "\n",
    "print(f\"\\nTraining response matrix: {train_responses.shape}\")\n",
    "print(f\"  Memory: {train_responses.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed testing responses...\n",
      "\n",
      "Testing response matrix: (13560, 10000)\n",
      "  Memory: 542.4 MB\n"
     ]
    }
   ],
   "source": [
    "if test_response_file.exists():\n",
    "    print(\"Loading pre-computed testing responses...\")\n",
    "    test_responses = np.load(test_response_file)\n",
    "else:\n",
    "    print(\"Computing testing feature responses...\")\n",
    "    print(\"This may take several minutes...\")\n",
    "    test_responses = compute_feature_responses(features, X_test)\n",
    "    np.save(test_response_file, test_responses)\n",
    "    print(f\"Saved to {test_response_file}\")\n",
    "\n",
    "print(f\"\\nTesting response matrix: {test_responses.shape}\")\n",
    "print(f\"  Memory: {test_responses.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train AdaBoost Classifier\n",
    "\n",
    "Train with T=50 rounds (V1 simplified version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoost with T=50 rounds...\n",
      "This will take a while...\n",
      "\n",
      "============================================================\n",
      "Training AdaBoost with T=50 rounds\n",
      "  Samples: 4794 (negatives: 3995, positives: 799)\n",
      "============================================================\n",
      "\n",
      "Initial weights sum: 1.000000\n",
      "  Negative samples: 3995 x 0.000125 = 0.500000\n",
      "  Positive samples: 799 x 0.000626 = 0.500000\n",
      "\n",
      "--- Round 1/50 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 831, error: 0.2372\n",
      "  Epsilon: 0.237171\n",
      "  Beta: 0.310911\n",
      "  Alpha: 1.168250\n",
      "\n",
      "--- Round 2/50 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9901, error: 0.3403\n",
      "  Epsilon: 0.340311\n",
      "  Beta: 0.515865\n",
      "  Alpha: 0.661910\n",
      "\n",
      "--- Round 3/50 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8751, error: 0.3344\n",
      "  Epsilon: 0.334411\n",
      "  Beta: 0.502428\n",
      "  Alpha: 0.688303\n",
      "\n",
      "--- Round 4/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3801, error: 0.3920\n",
      "  Epsilon: 0.391950\n",
      "  Beta: 0.644602\n",
      "  Alpha: 0.439122\n",
      "\n",
      "--- Round 5/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1344, error: 0.3826\n",
      "  Epsilon: 0.382581\n",
      "  Beta: 0.619647\n",
      "  Alpha: 0.478606\n",
      "\n",
      "--- Round 6/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1347, error: 0.3829\n",
      "  Epsilon: 0.382877\n",
      "  Beta: 0.620424\n",
      "  Alpha: 0.477352\n",
      "\n",
      "--- Round 7/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2371, error: 0.3924\n",
      "  Epsilon: 0.392371\n",
      "  Beta: 0.645740\n",
      "  Alpha: 0.437358\n",
      "\n",
      "--- Round 8/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9666, error: 0.3843\n",
      "  Epsilon: 0.384268\n",
      "  Beta: 0.624082\n",
      "  Alpha: 0.471473\n",
      "\n",
      "--- Round 9/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9785, error: 0.4057\n",
      "  Epsilon: 0.405681\n",
      "  Beta: 0.682597\n",
      "  Alpha: 0.381851\n",
      "\n",
      "--- Round 10/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2245, error: 0.4137\n",
      "  Epsilon: 0.413660\n",
      "  Beta: 0.705494\n",
      "  Alpha: 0.348857\n",
      "  Training accuracy: 82.29%\n",
      "\n",
      "--- Round 11/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7322, error: 0.4021\n",
      "  Epsilon: 0.402068\n",
      "  Beta: 0.672430\n",
      "  Alpha: 0.396857\n",
      "\n",
      "--- Round 12/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 991, error: 0.3941\n",
      "  Epsilon: 0.394085\n",
      "  Beta: 0.650397\n",
      "  Alpha: 0.430172\n",
      "\n",
      "--- Round 13/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 936, error: 0.4017\n",
      "  Epsilon: 0.401707\n",
      "  Beta: 0.671422\n",
      "  Alpha: 0.398357\n",
      "\n",
      "--- Round 14/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2711, error: 0.4209\n",
      "  Epsilon: 0.420912\n",
      "  Beta: 0.726855\n",
      "  Alpha: 0.319029\n",
      "\n",
      "--- Round 15/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3194, error: 0.4125\n",
      "  Epsilon: 0.412467\n",
      "  Beta: 0.702033\n",
      "  Alpha: 0.353775\n",
      "\n",
      "--- Round 16/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8667, error: 0.4286\n",
      "  Epsilon: 0.428614\n",
      "  Beta: 0.750129\n",
      "  Alpha: 0.287510\n",
      "\n",
      "--- Round 17/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1256, error: 0.4275\n",
      "  Epsilon: 0.427545\n",
      "  Beta: 0.746863\n",
      "  Alpha: 0.291874\n",
      "\n",
      "--- Round 18/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1237, error: 0.4237\n",
      "  Epsilon: 0.423741\n",
      "  Beta: 0.735331\n",
      "  Alpha: 0.307435\n",
      "\n",
      "--- Round 19/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7720, error: 0.4213\n",
      "  Epsilon: 0.421270\n",
      "  Beta: 0.727920\n",
      "  Alpha: 0.317564\n",
      "\n",
      "--- Round 20/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 5125, error: 0.4290\n",
      "  Epsilon: 0.428962\n",
      "  Beta: 0.751198\n",
      "  Alpha: 0.286086\n",
      "  Training accuracy: 85.17%\n",
      "\n",
      "--- Round 21/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8121, error: 0.4319\n",
      "  Epsilon: 0.431906\n",
      "  Beta: 0.760273\n",
      "  Alpha: 0.274078\n",
      "\n",
      "--- Round 22/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3, error: 0.4275\n",
      "  Epsilon: 0.427501\n",
      "  Beta: 0.746727\n",
      "  Alpha: 0.292056\n",
      "\n",
      "--- Round 23/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8947, error: 0.4046\n",
      "  Epsilon: 0.404593\n",
      "  Beta: 0.679523\n",
      "  Alpha: 0.386365\n",
      "\n",
      "--- Round 24/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1032, error: 0.4263\n",
      "  Epsilon: 0.426295\n",
      "  Beta: 0.743055\n",
      "  Alpha: 0.296986\n",
      "\n",
      "--- Round 25/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8783, error: 0.4147\n",
      "  Epsilon: 0.414666\n",
      "  Beta: 0.708428\n",
      "  Alpha: 0.344707\n",
      "\n",
      "--- Round 26/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9912, error: 0.4340\n",
      "  Epsilon: 0.434028\n",
      "  Beta: 0.766873\n",
      "  Alpha: 0.265435\n",
      "\n",
      "--- Round 27/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 5109, error: 0.4356\n",
      "  Epsilon: 0.435592\n",
      "  Beta: 0.771768\n",
      "  Alpha: 0.259071\n",
      "\n",
      "--- Round 28/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 787, error: 0.4199\n",
      "  Epsilon: 0.419908\n",
      "  Beta: 0.723865\n",
      "  Alpha: 0.323151\n",
      "\n",
      "--- Round 29/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 5141, error: 0.4286\n",
      "  Epsilon: 0.428563\n",
      "  Beta: 0.749973\n",
      "  Alpha: 0.287718\n",
      "\n",
      "--- Round 30/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7583, error: 0.4296\n",
      "  Epsilon: 0.429583\n",
      "  Beta: 0.753103\n",
      "  Alpha: 0.283553\n",
      "  Training accuracy: 86.88%\n",
      "\n",
      "--- Round 31/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8498, error: 0.4206\n",
      "  Epsilon: 0.420575\n",
      "  Beta: 0.725849\n",
      "  Alpha: 0.320414\n",
      "\n",
      "--- Round 32/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9426, error: 0.4370\n",
      "  Epsilon: 0.436996\n",
      "  Beta: 0.776185\n",
      "  Alpha: 0.253364\n",
      "\n",
      "--- Round 33/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9871, error: 0.4201\n",
      "  Epsilon: 0.420070\n",
      "  Beta: 0.724345\n",
      "  Alpha: 0.322487\n",
      "\n",
      "--- Round 34/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8800, error: 0.4356\n",
      "  Epsilon: 0.435585\n",
      "  Beta: 0.771747\n",
      "  Alpha: 0.259099\n",
      "\n",
      "--- Round 35/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8351, error: 0.4385\n",
      "  Epsilon: 0.438462\n",
      "  Beta: 0.780822\n",
      "  Alpha: 0.247408\n",
      "\n",
      "--- Round 36/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3553, error: 0.4353\n",
      "  Epsilon: 0.435299\n",
      "  Beta: 0.770848\n",
      "  Alpha: 0.260264\n",
      "\n",
      "--- Round 37/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7113, error: 0.4360\n",
      "  Epsilon: 0.435979\n",
      "  Beta: 0.772985\n",
      "  Alpha: 0.257496\n",
      "\n",
      "--- Round 38/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8642, error: 0.4245\n",
      "  Epsilon: 0.424548\n",
      "  Beta: 0.737763\n",
      "  Alpha: 0.304132\n",
      "\n",
      "--- Round 39/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3708, error: 0.4396\n",
      "  Epsilon: 0.439601\n",
      "  Beta: 0.784443\n",
      "  Alpha: 0.242781\n",
      "\n",
      "--- Round 40/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1969, error: 0.4365\n",
      "  Epsilon: 0.436482\n",
      "  Beta: 0.774565\n",
      "  Alpha: 0.255453\n",
      "  Training accuracy: 88.40%\n",
      "\n",
      "--- Round 41/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9677, error: 0.4307\n",
      "  Epsilon: 0.430704\n",
      "  Beta: 0.756556\n",
      "  Alpha: 0.278979\n",
      "\n",
      "--- Round 42/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8386, error: 0.4426\n",
      "  Epsilon: 0.442572\n",
      "  Beta: 0.793955\n",
      "  Alpha: 0.230729\n",
      "\n",
      "--- Round 43/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 5348, error: 0.4374\n",
      "  Epsilon: 0.437378\n",
      "  Beta: 0.777391\n",
      "  Alpha: 0.251811\n",
      "\n",
      "--- Round 44/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2074, error: 0.4334\n",
      "  Epsilon: 0.433426\n",
      "  Beta: 0.764994\n",
      "  Alpha: 0.267887\n",
      "\n",
      "--- Round 45/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 6562, error: 0.4368\n",
      "  Epsilon: 0.436759\n",
      "  Beta: 0.775438\n",
      "  Alpha: 0.254328\n",
      "\n",
      "--- Round 46/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8165, error: 0.4390\n",
      "  Epsilon: 0.438974\n",
      "  Beta: 0.782448\n",
      "  Alpha: 0.245328\n",
      "\n",
      "--- Round 47/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1024, error: 0.4421\n",
      "  Epsilon: 0.442134\n",
      "  Beta: 0.792544\n",
      "  Alpha: 0.232507\n",
      "\n",
      "--- Round 48/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9242, error: 0.4373\n",
      "  Epsilon: 0.437337\n",
      "  Beta: 0.777263\n",
      "  Alpha: 0.251976\n",
      "\n",
      "--- Round 49/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2960, error: 0.4277\n",
      "  Epsilon: 0.427700\n",
      "  Beta: 0.747337\n",
      "  Alpha: 0.291239\n",
      "\n",
      "--- Round 50/50 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2298, error: 0.4331\n",
      "  Epsilon: 0.433123\n",
      "  Beta: 0.764052\n",
      "  Alpha: 0.269120\n",
      "  Training accuracy: 89.38%\n",
      "\n",
      "============================================================\n",
      "AdaBoost Training Complete!\n",
      "  Selected 50 weak classifiers\n",
      "  Total alpha: 17.2517\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Train AdaBoost\n",
    "T = 50  # V1: 50 weak classifiers\n",
    "\n",
    "print(f\"Training AdaBoost with T={T} rounds...\")\n",
    "print(\"This will take a while...\\n\")\n",
    "\n",
    "classifier = train_adaboost(\n",
    "    feature_response_matrix=train_responses,\n",
    "    labels=y_train,\n",
    "    features=features,\n",
    "    T=T,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on TRAINING set...\n",
      "\n",
      "============================================================\n",
      "Evaluation Metrics\n",
      "============================================================\n",
      "Accuracy:  89.38%\n",
      "Precision: 62.59%\n",
      "Recall:    90.24%\n",
      "F1 Score:  73.91%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:   721  FP:   431\n",
      "  FN:    78  TN:  3564\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating on TRAINING set...\")\n",
    "train_metrics = evaluate_classifier(classifier, train_responses, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on TEST set...\n",
      "\n",
      "============================================================\n",
      "Evaluation Metrics\n",
      "============================================================\n",
      "Accuracy:  84.97%\n",
      "Precision: 53.34%\n",
      "Recall:    78.45%\n",
      "F1 Score:  63.50%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:  1773  FP:  1551\n",
      "  FN:   487  TN:  9749\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating on TEST set...\")\n",
    "test_metrics = evaluate_classifier(classifier, test_responses, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Trained Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classifier to ..\\data\\models\\adaboost_v1_T50.pkl\n",
      "\n",
      "Model saved to ..\\data\\models\\adaboost_v1_T50.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('../data/models/adaboost_v1_T50.pkl')\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "classifier.save(model_path)\n",
    "print(f\"\\nModel saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Selected Features\n",
    "\n",
    "Show the features AdaBoost selected as most discriminative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from features.haar_features import visualize_feature\n",
    "\n",
    "# Show first 12 selected features\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "fig.suptitle('Top 12 Features Selected by AdaBoost', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i >= len(classifier.weak_classifiers):\n",
    "        break\n",
    "    \n",
    "    weak_clf = classifier.weak_classifiers[i]\n",
    "    feature = features[weak_clf.feature_idx]\n",
    "    alpha = classifier.alphas[i]\n",
    "    \n",
    "    # Visualize feature\n",
    "    feat_img = visualize_feature(feature, window_size=16)\n",
    "    ax.imshow(feat_img, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    ax.set_title(f'Feature {i+1}\\nalpha={alpha:.2f}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/selected_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADABOOST V1 RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Configuration:\n",
      "  Haar features: 10,000\n",
      "  AdaBoost rounds (T): 50\n",
      "  Weak classifiers selected: 50\n",
      "\n",
      "Training Performance:\n",
      "  Accuracy:  89.38%\n",
      "  Precision: 62.59%\n",
      "  Recall:    90.24%\n",
      "  F1 Score:  73.91%\n",
      "\n",
      "Test Performance:\n",
      "  Accuracy:  84.97%\n",
      "  Precision: 53.34%\n",
      "  Recall:    78.45%\n",
      "  F1 Score:  63.50%\n",
      "\n",
      "============================================================\n",
      "[OK] V1 Milestone achieved! (>70% accuracy)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ADABOOST V1 RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Haar features: {len(features):,}\")\n",
    "print(f\"  AdaBoost rounds (T): {T}\")\n",
    "print(f\"  Weak classifiers selected: {len(classifier.weak_classifiers)}\")\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  Accuracy:  {train_metrics['accuracy']:.2%}\")\n",
    "print(f\"  Precision: {train_metrics['precision']:.2%}\")\n",
    "print(f\"  Recall:    {train_metrics['recall']:.2%}\")\n",
    "print(f\"  F1 Score:  {train_metrics['f1']:.2%}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  Accuracy:  {test_metrics['accuracy']:.2%}\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.2%}\")\n",
    "print(f\"  Recall:    {test_metrics['recall']:.2%}\")\n",
    "print(f\"  F1 Score:  {test_metrics['f1']:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if test_metrics['accuracy'] >= 0.70:\n",
    "    print(\"[OK] V1 Milestone achieved! (>70% accuracy)\")\n",
    "else:\n",
    "    print(\"Note: May need more features or rounds for better performance\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **V1 Complete**: If accuracy >70%, V1 simplified version is working!\n",
    "2. **Cascade**: Implement 2-stage cascade for improved false positive reduction\n",
    "3. **V2 Scale-up**: Increase to 50k features and T=200 for better performance\n",
    "4. **Detection**: Test on actual images with sliding windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ell715-assignment-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
