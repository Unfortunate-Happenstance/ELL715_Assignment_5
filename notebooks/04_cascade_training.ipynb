{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Training for Viola-Jones Face Detector\n",
    "\n",
    "Train 2-stage cascade classifier to reduce false positives.\n",
    "\n",
    "**V1 Configuration**:\n",
    "- Stage 1: T=10 (reject ~50% non-faces, keep >99% faces)\n",
    "- Stage 2: T=40 (final discriminative stage)\n",
    "- Combined: High detection rate with low FP rate\n",
    "\n",
    "**AI Usage**: Notebook structure assisted by Claude Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from classifiers.cascade import train_cascade, evaluate_cascade, CascadeClassifier\n",
    "from features.haar_features import generate_haar_features\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pre-computed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset labels...\n",
      "Training: 799 faces, 3995 non-faces\n",
      "Testing: 2260 faces, 11300 non-faces\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset labels...\")\n",
    "\n",
    "# Load training data\n",
    "with open('../data/processed/train_faces.pkl', 'rb') as f:\n",
    "    train_faces = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/train_nonfaces.pkl', 'rb') as f:\n",
    "    train_nonfaces = pickle.load(f)\n",
    "\n",
    "# Create labels\n",
    "y_train = np.concatenate([\n",
    "    np.ones(len(train_faces), dtype=int),\n",
    "    np.zeros(len(train_nonfaces), dtype=int)\n",
    "])\n",
    "\n",
    "# Load testing data\n",
    "with open('../data/processed/test_faces.pkl', 'rb') as f:\n",
    "    test_faces = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/test_nonfaces.pkl', 'rb') as f:\n",
    "    test_nonfaces = pickle.load(f)\n",
    "\n",
    "y_test = np.concatenate([\n",
    "    np.ones(len(test_faces), dtype=int),\n",
    "    np.zeros(len(test_nonfaces), dtype=int)\n",
    "])\n",
    "\n",
    "print(f\"Training: {len(train_faces)} faces, {len(train_nonfaces)} non-faces\")\n",
    "print(f\"Testing: {len(test_faces)} faces, {len(test_nonfaces)} non-faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading pre-computed feature responses...\n",
      "Training responses: (4794, 10000)\n",
      "Testing responses: (13560, 10000)\n",
      "Training responses: (4794, 10000)\n",
      "Testing responses: (13560, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-computed feature responses\n",
    "print(\"\\nLoading pre-computed feature responses...\")\n",
    "train_responses = np.load('../data/processed/train_responses_10k.npy')\n",
    "test_responses = np.load('../data/processed/test_responses_10k.npy')\n",
    "\n",
    "print(f\"Training responses: {train_responses.shape}\")\n",
    "print(f\"Testing responses: {test_responses.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Haar features (same as training)...\n",
      "Generating Haar features for 16Ã—16 window...\n",
      "  Generating 2-rectangle horizontal features...\n",
      "  Generating 2-rectangle vertical features...\n",
      "Generated 10000 features\n"
     ]
    }
   ],
   "source": [
    "# Load features\n",
    "print(\"\\nGenerating Haar features (same as training)...\")\n",
    "features = generate_haar_features(window_size=16, max_features=10000)\n",
    "print(f\"Generated {len(features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Cascade Configuration\n",
    "\n",
    "**2-Stage Cascade**:\n",
    "- Stage 1: Fast filter (T=10, high recall)\n",
    "- Stage 2: Discriminative (T=40, balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cascade Configuration:\n",
      "  Stage 1: T=10, FPR=50.0%, TPR=99.5%\n",
      "  Stage 2: T=40, FPR=1.0%, TPR=99.0%\n"
     ]
    }
   ],
   "source": [
    "stage_configs = [\n",
    "    {\n",
    "        'T': 10,\n",
    "        'target_fpr': 0.5,    # Reject 50% of non-faces\n",
    "        'target_tpr': 0.995   # Keep 99.5% of faces\n",
    "    },\n",
    "    {\n",
    "        'T': 40,\n",
    "        'target_fpr': 0.01,   # Very low FP rate for final stage\n",
    "        'target_tpr': 0.99    # 99% face detection\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Cascade Configuration:\")\n",
    "for i, config in enumerate(stage_configs, 1):\n",
    "    print(f\"  Stage {i}: T={config['T']}, FPR={config['target_fpr']:.1%}, TPR={config['target_tpr']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Cascade\n",
    "\n",
    "**This will take several minutes**\n",
    "- Stage 1: Train on full dataset\n",
    "- Stage 2: Train on faces + FPs from Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Cascade with 2 stages\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Training Stage 1/2\n",
      "  T=10 weak classifiers\n",
      "  Target FPR: 50.0%, Target TPR: 99.5%\n",
      "  Training samples: 4794\n",
      "    Faces: 799\n",
      "    Non-faces: 3995\n",
      "============================================================\n",
      "============================================================\n",
      "Training AdaBoost with T=10 rounds\n",
      "  Samples: 4794 (negatives: 3995, positives: 799)\n",
      "============================================================\n",
      "\n",
      "Initial weights sum: 1.000000\n",
      "  Negative samples: 3995 x 0.000125 = 0.500000\n",
      "  Positive samples: 799 x 0.000626 = 0.500000\n",
      "\n",
      "--- Round 1/10 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 831, error: 0.2372\n",
      "  Epsilon: 0.237171\n",
      "  Beta: 0.310911\n",
      "  Alpha: 1.168250\n",
      "\n",
      "--- Round 2/10 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 831, error: 0.2372\n",
      "  Epsilon: 0.237171\n",
      "  Beta: 0.310911\n",
      "  Alpha: 1.168250\n",
      "\n",
      "--- Round 2/10 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9901, error: 0.3403\n",
      "  Epsilon: 0.340311\n",
      "  Beta: 0.515865\n",
      "  Alpha: 0.661910\n",
      "\n",
      "--- Round 3/10 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9901, error: 0.3403\n",
      "  Epsilon: 0.340311\n",
      "  Beta: 0.515865\n",
      "  Alpha: 0.661910\n",
      "\n",
      "--- Round 3/10 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8751, error: 0.3344\n",
      "  Epsilon: 0.334411\n",
      "  Beta: 0.502428\n",
      "  Alpha: 0.688303\n",
      "\n",
      "--- Round 4/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8751, error: 0.3344\n",
      "  Epsilon: 0.334411\n",
      "  Beta: 0.502428\n",
      "  Alpha: 0.688303\n",
      "\n",
      "--- Round 4/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3801, error: 0.3920\n",
      "  Epsilon: 0.391950\n",
      "  Beta: 0.644602\n",
      "  Alpha: 0.439122\n",
      "\n",
      "--- Round 5/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3801, error: 0.3920\n",
      "  Epsilon: 0.391950\n",
      "  Beta: 0.644602\n",
      "  Alpha: 0.439122\n",
      "\n",
      "--- Round 5/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1344, error: 0.3826\n",
      "  Epsilon: 0.382581\n",
      "  Beta: 0.619647\n",
      "  Alpha: 0.478606\n",
      "\n",
      "--- Round 6/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1344, error: 0.3826\n",
      "  Epsilon: 0.382581\n",
      "  Beta: 0.619647\n",
      "  Alpha: 0.478606\n",
      "\n",
      "--- Round 6/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1347, error: 0.3829\n",
      "  Epsilon: 0.382877\n",
      "  Beta: 0.620424\n",
      "  Alpha: 0.477352\n",
      "\n",
      "--- Round 7/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1347, error: 0.3829\n",
      "  Epsilon: 0.382877\n",
      "  Beta: 0.620424\n",
      "  Alpha: 0.477352\n",
      "\n",
      "--- Round 7/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2371, error: 0.3924\n",
      "  Epsilon: 0.392371\n",
      "  Beta: 0.645740\n",
      "  Alpha: 0.437358\n",
      "\n",
      "--- Round 8/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2371, error: 0.3924\n",
      "  Epsilon: 0.392371\n",
      "  Beta: 0.645740\n",
      "  Alpha: 0.437358\n",
      "\n",
      "--- Round 8/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9666, error: 0.3843\n",
      "  Epsilon: 0.384268\n",
      "  Beta: 0.624082\n",
      "  Alpha: 0.471473\n",
      "\n",
      "--- Round 9/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9666, error: 0.3843\n",
      "  Epsilon: 0.384268\n",
      "  Beta: 0.624082\n",
      "  Alpha: 0.471473\n",
      "\n",
      "--- Round 9/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9785, error: 0.4057\n",
      "  Epsilon: 0.405681\n",
      "  Beta: 0.682597\n",
      "  Alpha: 0.381851\n",
      "\n",
      "--- Round 10/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9785, error: 0.4057\n",
      "  Epsilon: 0.405681\n",
      "  Beta: 0.682597\n",
      "  Alpha: 0.381851\n",
      "\n",
      "--- Round 10/10 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2245, error: 0.4137\n",
      "  Epsilon: 0.413660\n",
      "  Beta: 0.705494\n",
      "  Alpha: 0.348857\n",
      "  Training accuracy: 82.29%\n",
      "\n",
      "============================================================\n",
      "AdaBoost Training Complete!\n",
      "  Selected 10 weak classifiers\n",
      "  Total alpha: 5.5531\n",
      "============================================================\n",
      "\n",
      "Adjusting threshold for Stage 1...\n",
      "  Adjusted threshold: 0.3068\n",
      "\n",
      "Stage 1 Performance:\n",
      "  TPR (Detection Rate): 99.62%\n",
      "  FPR (False Positive Rate): 54.42%\n",
      "  Faces passing: 796/799\n",
      "  Non-faces rejected: 1821/3995\n",
      "\n",
      "Preparing for Stage 2:\n",
      "  Samples passing to next stage: 2970\n",
      "    Faces: 796\n",
      "    Non-faces (FPs): 2174\n",
      "\n",
      "============================================================\n",
      "Training Stage 2/2\n",
      "  T=40 weak classifiers\n",
      "  Target FPR: 1.0%, Target TPR: 99.0%\n",
      "  Training samples: 2970\n",
      "    Faces: 796\n",
      "    Non-faces: 2174\n",
      "============================================================\n",
      "============================================================\n",
      "Training AdaBoost with T=40 rounds\n",
      "  Samples: 2970 (negatives: 2174, positives: 796)\n",
      "============================================================\n",
      "\n",
      "Initial weights sum: 1.000000\n",
      "  Negative samples: 2174 x 0.000230 = 0.500000\n",
      "  Positive samples: 796 x 0.000628 = 0.500000\n",
      "\n",
      "--- Round 1/40 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2245, error: 0.4137\n",
      "  Epsilon: 0.413660\n",
      "  Beta: 0.705494\n",
      "  Alpha: 0.348857\n",
      "  Training accuracy: 82.29%\n",
      "\n",
      "============================================================\n",
      "AdaBoost Training Complete!\n",
      "  Selected 10 weak classifiers\n",
      "  Total alpha: 5.5531\n",
      "============================================================\n",
      "\n",
      "Adjusting threshold for Stage 1...\n",
      "  Adjusted threshold: 0.3068\n",
      "\n",
      "Stage 1 Performance:\n",
      "  TPR (Detection Rate): 99.62%\n",
      "  FPR (False Positive Rate): 54.42%\n",
      "  Faces passing: 796/799\n",
      "  Non-faces rejected: 1821/3995\n",
      "\n",
      "Preparing for Stage 2:\n",
      "  Samples passing to next stage: 2970\n",
      "    Faces: 796\n",
      "    Non-faces (FPs): 2174\n",
      "\n",
      "============================================================\n",
      "Training Stage 2/2\n",
      "  T=40 weak classifiers\n",
      "  Target FPR: 1.0%, Target TPR: 99.0%\n",
      "  Training samples: 2970\n",
      "    Faces: 796\n",
      "    Non-faces: 2174\n",
      "============================================================\n",
      "============================================================\n",
      "Training AdaBoost with T=40 rounds\n",
      "  Samples: 2970 (negatives: 2174, positives: 796)\n",
      "============================================================\n",
      "\n",
      "Initial weights sum: 1.000000\n",
      "  Negative samples: 2174 x 0.000230 = 0.500000\n",
      "  Positive samples: 796 x 0.000628 = 0.500000\n",
      "\n",
      "--- Round 1/40 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1007, error: 0.3141\n",
      "  Epsilon: 0.314102\n",
      "  Beta: 0.457942\n",
      "  Alpha: 0.781013\n",
      "\n",
      "--- Round 2/40 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1007, error: 0.3141\n",
      "  Epsilon: 0.314102\n",
      "  Beta: 0.457942\n",
      "  Alpha: 0.781013\n",
      "\n",
      "--- Round 2/40 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8732, error: 0.3664\n",
      "  Epsilon: 0.366365\n",
      "  Beta: 0.578194\n",
      "  Alpha: 0.547845\n",
      "\n",
      "--- Round 3/40 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8732, error: 0.3664\n",
      "  Epsilon: 0.366365\n",
      "  Beta: 0.578194\n",
      "  Alpha: 0.547845\n",
      "\n",
      "--- Round 3/40 ---\n",
      "  Normalized weights sum: 1.000000\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2094, error: 0.3845\n",
      "  Epsilon: 0.384461\n",
      "  Beta: 0.624592\n",
      "  Alpha: 0.470657\n",
      "\n",
      "--- Round 4/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2094, error: 0.3845\n",
      "  Epsilon: 0.384461\n",
      "  Beta: 0.624592\n",
      "  Alpha: 0.470657\n",
      "\n",
      "--- Round 4/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9563, error: 0.4006\n",
      "  Epsilon: 0.400602\n",
      "  Beta: 0.668341\n",
      "  Alpha: 0.402957\n",
      "\n",
      "--- Round 5/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9563, error: 0.4006\n",
      "  Epsilon: 0.400602\n",
      "  Beta: 0.668341\n",
      "  Alpha: 0.402957\n",
      "\n",
      "--- Round 5/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2711, error: 0.4015\n",
      "  Epsilon: 0.401549\n",
      "  Beta: 0.670980\n",
      "  Alpha: 0.399017\n",
      "\n",
      "--- Round 6/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2711, error: 0.4015\n",
      "  Epsilon: 0.401549\n",
      "  Beta: 0.670980\n",
      "  Alpha: 0.399017\n",
      "\n",
      "--- Round 6/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7322, error: 0.4038\n",
      "  Epsilon: 0.403847\n",
      "  Beta: 0.677423\n",
      "  Alpha: 0.389459\n",
      "\n",
      "--- Round 7/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7322, error: 0.4038\n",
      "  Epsilon: 0.403847\n",
      "  Beta: 0.677423\n",
      "  Alpha: 0.389459\n",
      "\n",
      "--- Round 7/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9215, error: 0.4213\n",
      "  Epsilon: 0.421288\n",
      "  Beta: 0.727975\n",
      "  Alpha: 0.317488\n",
      "\n",
      "--- Round 8/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9215, error: 0.4213\n",
      "  Epsilon: 0.421288\n",
      "  Beta: 0.727975\n",
      "  Alpha: 0.317488\n",
      "\n",
      "--- Round 8/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8800, error: 0.4231\n",
      "  Epsilon: 0.423099\n",
      "  Beta: 0.733398\n",
      "  Alpha: 0.310066\n",
      "\n",
      "--- Round 9/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8800, error: 0.4231\n",
      "  Epsilon: 0.423099\n",
      "  Beta: 0.733398\n",
      "  Alpha: 0.310066\n",
      "\n",
      "--- Round 9/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 120, error: 0.4236\n",
      "  Epsilon: 0.423624\n",
      "  Beta: 0.734980\n",
      "  Alpha: 0.307912\n",
      "\n",
      "--- Round 10/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 120, error: 0.4236\n",
      "  Epsilon: 0.423624\n",
      "  Beta: 0.734980\n",
      "  Alpha: 0.307912\n",
      "\n",
      "--- Round 10/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3166, error: 0.4179\n",
      "  Epsilon: 0.417924\n",
      "  Beta: 0.717988\n",
      "  Alpha: 0.331303\n",
      "  Training accuracy: 78.72%\n",
      "\n",
      "--- Round 11/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3166, error: 0.4179\n",
      "  Epsilon: 0.417924\n",
      "  Beta: 0.717988\n",
      "  Alpha: 0.331303\n",
      "  Training accuracy: 78.72%\n",
      "\n",
      "--- Round 11/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2703, error: 0.4184\n",
      "  Epsilon: 0.418447\n",
      "  Beta: 0.719535\n",
      "  Alpha: 0.329150\n",
      "\n",
      "--- Round 12/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2703, error: 0.4184\n",
      "  Epsilon: 0.418447\n",
      "  Beta: 0.719535\n",
      "  Alpha: 0.329150\n",
      "\n",
      "--- Round 12/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 6524, error: 0.4180\n",
      "  Epsilon: 0.418038\n",
      "  Beta: 0.718324\n",
      "  Alpha: 0.330835\n",
      "\n",
      "--- Round 13/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 6524, error: 0.4180\n",
      "  Epsilon: 0.418038\n",
      "  Beta: 0.718324\n",
      "  Alpha: 0.330835\n",
      "\n",
      "--- Round 13/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8182, error: 0.4224\n",
      "  Epsilon: 0.422413\n",
      "  Beta: 0.731342\n",
      "  Alpha: 0.312874\n",
      "\n",
      "--- Round 14/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8182, error: 0.4224\n",
      "  Epsilon: 0.422413\n",
      "  Beta: 0.731342\n",
      "  Alpha: 0.312874\n",
      "\n",
      "--- Round 14/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7583, error: 0.4237\n",
      "  Epsilon: 0.423667\n",
      "  Beta: 0.735108\n",
      "  Alpha: 0.307737\n",
      "\n",
      "--- Round 15/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7583, error: 0.4237\n",
      "  Epsilon: 0.423667\n",
      "  Beta: 0.735108\n",
      "  Alpha: 0.307737\n",
      "\n",
      "--- Round 15/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9345, error: 0.4072\n",
      "  Epsilon: 0.407218\n",
      "  Beta: 0.686961\n",
      "  Alpha: 0.375478\n",
      "\n",
      "--- Round 16/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9345, error: 0.4072\n",
      "  Epsilon: 0.407218\n",
      "  Beta: 0.686961\n",
      "  Alpha: 0.375478\n",
      "\n",
      "--- Round 16/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7720, error: 0.4110\n",
      "  Epsilon: 0.411014\n",
      "  Beta: 0.697833\n",
      "  Alpha: 0.359776\n",
      "\n",
      "--- Round 17/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7720, error: 0.4110\n",
      "  Epsilon: 0.411014\n",
      "  Beta: 0.697833\n",
      "  Alpha: 0.359776\n",
      "\n",
      "--- Round 17/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8092, error: 0.4279\n",
      "  Epsilon: 0.427880\n",
      "  Beta: 0.747884\n",
      "  Alpha: 0.290508\n",
      "\n",
      "--- Round 18/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8092, error: 0.4279\n",
      "  Epsilon: 0.427880\n",
      "  Beta: 0.747884\n",
      "  Alpha: 0.290508\n",
      "\n",
      "--- Round 18/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 799, error: 0.4231\n",
      "  Epsilon: 0.423098\n",
      "  Beta: 0.733398\n",
      "  Alpha: 0.310067\n",
      "\n",
      "--- Round 19/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 799, error: 0.4231\n",
      "  Epsilon: 0.423098\n",
      "  Beta: 0.733398\n",
      "  Alpha: 0.310067\n",
      "\n",
      "--- Round 19/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 11, error: 0.4188\n",
      "  Epsilon: 0.418808\n",
      "  Beta: 0.720602\n",
      "  Alpha: 0.327668\n",
      "\n",
      "--- Round 20/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 11, error: 0.4188\n",
      "  Epsilon: 0.418808\n",
      "  Beta: 0.720602\n",
      "  Alpha: 0.327668\n",
      "\n",
      "--- Round 20/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3636, error: 0.4138\n",
      "  Epsilon: 0.413761\n",
      "  Beta: 0.705788\n",
      "  Alpha: 0.348441\n",
      "  Training accuracy: 80.10%\n",
      "\n",
      "--- Round 21/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3636, error: 0.4138\n",
      "  Epsilon: 0.413761\n",
      "  Beta: 0.705788\n",
      "  Alpha: 0.348441\n",
      "  Training accuracy: 80.10%\n",
      "\n",
      "--- Round 21/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9871, error: 0.4299\n",
      "  Epsilon: 0.429926\n",
      "  Beta: 0.754158\n",
      "  Alpha: 0.282154\n",
      "\n",
      "--- Round 22/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9871, error: 0.4299\n",
      "  Epsilon: 0.429926\n",
      "  Beta: 0.754158\n",
      "  Alpha: 0.282154\n",
      "\n",
      "--- Round 22/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9426, error: 0.4239\n",
      "  Epsilon: 0.423910\n",
      "  Beta: 0.735841\n",
      "  Alpha: 0.306741\n",
      "\n",
      "--- Round 23/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9426, error: 0.4239\n",
      "  Epsilon: 0.423910\n",
      "  Beta: 0.735841\n",
      "  Alpha: 0.306741\n",
      "\n",
      "--- Round 23/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9482, error: 0.4323\n",
      "  Epsilon: 0.432259\n",
      "  Beta: 0.761366\n",
      "  Alpha: 0.272641\n",
      "\n",
      "--- Round 24/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 9482, error: 0.4323\n",
      "  Epsilon: 0.432259\n",
      "  Beta: 0.761366\n",
      "  Alpha: 0.272641\n",
      "\n",
      "--- Round 24/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3165, error: 0.4240\n",
      "  Epsilon: 0.424027\n",
      "  Beta: 0.736193\n",
      "  Alpha: 0.306263\n",
      "\n",
      "--- Round 25/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3165, error: 0.4240\n",
      "  Epsilon: 0.424027\n",
      "  Beta: 0.736193\n",
      "  Alpha: 0.306263\n",
      "\n",
      "--- Round 25/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8828, error: 0.4189\n",
      "  Epsilon: 0.418930\n",
      "  Beta: 0.720963\n",
      "  Alpha: 0.327168\n",
      "\n",
      "--- Round 26/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8828, error: 0.4189\n",
      "  Epsilon: 0.418930\n",
      "  Beta: 0.720963\n",
      "  Alpha: 0.327168\n",
      "\n",
      "--- Round 26/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 747, error: 0.4236\n",
      "  Epsilon: 0.423591\n",
      "  Beta: 0.734878\n",
      "  Alpha: 0.308051\n",
      "\n",
      "--- Round 27/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 747, error: 0.4236\n",
      "  Epsilon: 0.423591\n",
      "  Beta: 0.734878\n",
      "  Alpha: 0.308051\n",
      "\n",
      "--- Round 27/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1025, error: 0.4303\n",
      "  Epsilon: 0.430339\n",
      "  Beta: 0.755429\n",
      "  Alpha: 0.280469\n",
      "\n",
      "--- Round 28/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1025, error: 0.4303\n",
      "  Epsilon: 0.430339\n",
      "  Beta: 0.755429\n",
      "  Alpha: 0.280469\n",
      "\n",
      "--- Round 28/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1237, error: 0.4325\n",
      "  Epsilon: 0.432454\n",
      "  Beta: 0.761971\n",
      "  Alpha: 0.271846\n",
      "\n",
      "--- Round 29/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1237, error: 0.4325\n",
      "  Epsilon: 0.432454\n",
      "  Beta: 0.761971\n",
      "  Alpha: 0.271846\n",
      "\n",
      "--- Round 29/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7038, error: 0.4217\n",
      "  Epsilon: 0.421722\n",
      "  Beta: 0.729272\n",
      "  Alpha: 0.315708\n",
      "\n",
      "--- Round 30/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7038, error: 0.4217\n",
      "  Epsilon: 0.421722\n",
      "  Beta: 0.729272\n",
      "  Alpha: 0.315708\n",
      "\n",
      "--- Round 30/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8698, error: 0.4332\n",
      "  Epsilon: 0.433202\n",
      "  Beta: 0.764295\n",
      "  Alpha: 0.268801\n",
      "  Training accuracy: 84.28%\n",
      "\n",
      "--- Round 31/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8698, error: 0.4332\n",
      "  Epsilon: 0.433202\n",
      "  Beta: 0.764295\n",
      "  Alpha: 0.268801\n",
      "  Training accuracy: 84.28%\n",
      "\n",
      "--- Round 31/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1032, error: 0.4305\n",
      "  Epsilon: 0.430464\n",
      "  Beta: 0.755814\n",
      "  Alpha: 0.279960\n",
      "\n",
      "--- Round 32/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 1032, error: 0.4305\n",
      "  Epsilon: 0.430464\n",
      "  Beta: 0.755814\n",
      "  Alpha: 0.279960\n",
      "\n",
      "--- Round 32/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8528, error: 0.4289\n",
      "  Epsilon: 0.428873\n",
      "  Beta: 0.750925\n",
      "  Alpha: 0.286450\n",
      "\n",
      "--- Round 33/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8528, error: 0.4289\n",
      "  Epsilon: 0.428873\n",
      "  Beta: 0.750925\n",
      "  Alpha: 0.286450\n",
      "\n",
      "--- Round 33/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8504, error: 0.4317\n",
      "  Epsilon: 0.431695\n",
      "  Beta: 0.759618\n",
      "  Alpha: 0.274940\n",
      "\n",
      "--- Round 34/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 8504, error: 0.4317\n",
      "  Epsilon: 0.431695\n",
      "  Beta: 0.759618\n",
      "  Alpha: 0.274940\n",
      "\n",
      "--- Round 34/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7119, error: 0.4382\n",
      "  Epsilon: 0.438208\n",
      "  Beta: 0.780019\n",
      "  Alpha: 0.248438\n",
      "\n",
      "--- Round 35/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 7119, error: 0.4382\n",
      "  Epsilon: 0.438208\n",
      "  Beta: 0.780019\n",
      "  Alpha: 0.248438\n",
      "\n",
      "--- Round 35/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3574, error: 0.4281\n",
      "  Epsilon: 0.428083\n",
      "  Beta: 0.748507\n",
      "  Alpha: 0.289675\n",
      "\n",
      "--- Round 36/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 3574, error: 0.4281\n",
      "  Epsilon: 0.428083\n",
      "  Beta: 0.748507\n",
      "  Alpha: 0.289675\n",
      "\n",
      "--- Round 36/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 4077, error: 0.4362\n",
      "  Epsilon: 0.436243\n",
      "  Beta: 0.773815\n",
      "  Alpha: 0.256423\n",
      "\n",
      "--- Round 37/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 4077, error: 0.4362\n",
      "  Epsilon: 0.436243\n",
      "  Beta: 0.773815\n",
      "  Alpha: 0.256423\n",
      "\n",
      "--- Round 37/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2098, error: 0.4295\n",
      "  Epsilon: 0.429497\n",
      "  Beta: 0.752838\n",
      "  Alpha: 0.283905\n",
      "\n",
      "--- Round 38/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 2098, error: 0.4295\n",
      "  Epsilon: 0.429497\n",
      "  Beta: 0.752838\n",
      "  Alpha: 0.283905\n",
      "\n",
      "--- Round 38/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 275, error: 0.4316\n",
      "  Epsilon: 0.431627\n",
      "  Beta: 0.759408\n",
      "  Alpha: 0.275216\n",
      "\n",
      "--- Round 39/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 275, error: 0.4316\n",
      "  Epsilon: 0.431627\n",
      "  Beta: 0.759408\n",
      "  Alpha: 0.275216\n",
      "\n",
      "--- Round 39/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 702, error: 0.4354\n",
      "  Epsilon: 0.435354\n",
      "  Beta: 0.771020\n",
      "  Alpha: 0.260041\n",
      "\n",
      "--- Round 40/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 702, error: 0.4354\n",
      "  Epsilon: 0.435354\n",
      "  Beta: 0.771020\n",
      "  Alpha: 0.260041\n",
      "\n",
      "--- Round 40/40 ---\n",
      "  Searching 10000 features for best weak classifier...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 1000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 2000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 3000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 4000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 5000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 6000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 7000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 8000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 9000/10000 features...\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 416, error: 0.4400\n",
      "  Epsilon: 0.440046\n",
      "  Beta: 0.785861\n",
      "  Alpha: 0.240975\n",
      "  Training accuracy: 85.42%\n",
      "\n",
      "============================================================\n",
      "AdaBoost Training Complete!\n",
      "  Selected 40 weak classifiers\n",
      "  Total alpha: 13.1861\n",
      "============================================================\n",
      "\n",
      "Adjusting threshold for Stage 2...\n",
      "  Adjusted threshold: 0.4406\n",
      "\n",
      "Stage 2 Performance:\n",
      "  TPR (Detection Rate): 99.12%\n",
      "  FPR (False Positive Rate): 39.79%\n",
      "  Faces passing: 789/796\n",
      "  Non-faces rejected: 1309/2174\n",
      "\n",
      "============================================================\n",
      "Cascade Training Complete!\n",
      "  Total stages: 2\n",
      "============================================================\n",
      "    Evaluated 10000/10000 features...\n",
      "  Best feature: 416, error: 0.4400\n",
      "  Epsilon: 0.440046\n",
      "  Beta: 0.785861\n",
      "  Alpha: 0.240975\n",
      "  Training accuracy: 85.42%\n",
      "\n",
      "============================================================\n",
      "AdaBoost Training Complete!\n",
      "  Selected 40 weak classifiers\n",
      "  Total alpha: 13.1861\n",
      "============================================================\n",
      "\n",
      "Adjusting threshold for Stage 2...\n",
      "  Adjusted threshold: 0.4406\n",
      "\n",
      "Stage 2 Performance:\n",
      "  TPR (Detection Rate): 99.12%\n",
      "  FPR (False Positive Rate): 39.79%\n",
      "  Faces passing: 789/796\n",
      "  Non-faces rejected: 1309/2174\n",
      "\n",
      "============================================================\n",
      "Cascade Training Complete!\n",
      "  Total stages: 2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "cascade = train_cascade(\n",
    "    train_responses,\n",
    "    y_train,\n",
    "    features,\n",
    "    stage_configs,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating cascade on TRAINING set...\n",
      "\n",
      "============================================================\n",
      "Cascade Evaluation Metrics\n",
      "============================================================\n",
      "Overall Performance:\n",
      "  Accuracy:  81.75%\n",
      "  Precision: 47.70%\n",
      "  Recall:    98.75%\n",
      "  F1 Score:  64.33%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:   789  FP:   865\n",
      "  FN:    10  TN:  3130\n",
      "\n",
      "Cascade Stage Statistics:\n",
      "  Stage 1:  4794 samples,  1824 rejected (38.0%)\n",
      "  Stage 2:  2970 samples,  1316 rejected (44.3%)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cascade Evaluation Metrics\n",
      "============================================================\n",
      "Overall Performance:\n",
      "  Accuracy:  81.75%\n",
      "  Precision: 47.70%\n",
      "  Recall:    98.75%\n",
      "  F1 Score:  64.33%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:   789  FP:   865\n",
      "  FN:    10  TN:  3130\n",
      "\n",
      "Cascade Stage Statistics:\n",
      "  Stage 1:  4794 samples,  1824 rejected (38.0%)\n",
      "  Stage 2:  2970 samples,  1316 rejected (44.3%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating cascade on TRAINING set...\")\n",
    "train_metrics = evaluate_cascade(cascade, train_responses, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating cascade on TEST set...\n",
      "\n",
      "============================================================\n",
      "Cascade Evaluation Metrics\n",
      "============================================================\n",
      "Overall Performance:\n",
      "  Accuracy:  74.92%\n",
      "  Precision: 39.04%\n",
      "  Recall:    89.91%\n",
      "  F1 Score:  54.44%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:  2032  FP:  3173\n",
      "  FN:   228  TN:  8127\n",
      "\n",
      "Cascade Stage Statistics:\n",
      "  Stage 1: 13560 samples,  4784 rejected (35.3%)\n",
      "  Stage 2:  8776 samples,  3571 rejected (40.7%)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cascade Evaluation Metrics\n",
      "============================================================\n",
      "Overall Performance:\n",
      "  Accuracy:  74.92%\n",
      "  Precision: 39.04%\n",
      "  Recall:    89.91%\n",
      "  F1 Score:  54.44%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:  2032  FP:  3173\n",
      "  FN:   228  TN:  8127\n",
      "\n",
      "Cascade Stage Statistics:\n",
      "  Stage 1: 13560 samples,  4784 rejected (35.3%)\n",
      "  Stage 2:  8776 samples,  3571 rejected (40.7%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating cascade on TEST set...\")\n",
    "test_metrics = evaluate_cascade(cascade, test_responses, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Cascade Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cascade to ..\\data\\models\\cascade_v1_2stage.pkl\n",
      "\n",
      "Cascade saved to ..\\data\\models\\cascade_v1_2stage.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('../data/models/cascade_v1_2stage.pkl')\n",
    "cascade.save(model_path)\n",
    "print(f\"\\nCascade saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare with Single AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading single AdaBoost model for comparison...\n",
      "\n",
      "Single AdaBoost (T=50) on TEST set:\n",
      "\n",
      "============================================================\n",
      "Evaluation Metrics\n",
      "============================================================\n",
      "Accuracy:  84.97%\n",
      "Precision: 53.34%\n",
      "Recall:    78.45%\n",
      "F1 Score:  63.50%\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:  1773  FP:  1551\n",
      "  FN:   487  TN:  9749\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "COMPARISON: Cascade vs Single AdaBoost\n",
      "============================================================\n",
      "Metric          Cascade         AdaBoost T=50  \n",
      "------------------------------------------------------------\n",
      "Accuracy        74.92%          84.97%         \n",
      "Precision       39.04%          53.34%         \n",
      "Recall          89.91%          78.45%         \n",
      "F1 Score        54.44%          63.50%         \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and compare with single AdaBoost\n",
    "from classifiers.adaboost import AdaBoostClassifier, evaluate_classifier\n",
    "\n",
    "adaboost_path = Path('../data/models/adaboost_v1_T50.pkl')\n",
    "if adaboost_path.exists():\n",
    "    print(\"Loading single AdaBoost model for comparison...\")\n",
    "    adaboost = AdaBoostClassifier.load(adaboost_path)\n",
    "    \n",
    "    print(\"\\nSingle AdaBoost (T=50) on TEST set:\")\n",
    "    adaboost_metrics = evaluate_classifier(adaboost, test_responses, y_test, verbose=True)\n",
    "    \n",
    "    # Comparison table\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPARISON: Cascade vs Single AdaBoost\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Metric':<15} {'Cascade':<15} {'AdaBoost T=50':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Accuracy':<15} {test_metrics['accuracy']:<15.2%} {adaboost_metrics['accuracy']:<15.2%}\")\n",
    "    print(f\"{'Precision':<15} {test_metrics['precision']:<15.2%} {adaboost_metrics['precision']:<15.2%}\")\n",
    "    print(f\"{'Recall':<15} {test_metrics['recall']:<15.2%} {adaboost_metrics['recall']:<15.2%}\")\n",
    "    print(f\"{'F1 Score':<15} {test_metrics['f1']:<15.2%} {adaboost_metrics['f1']:<15.2%}\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"Single AdaBoost model not found. Train it first using 03_adaboost_training.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Cascade Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stage-by-stage rejection rates\n",
    "stage_info = test_metrics['stage_info']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot: samples per stage\n",
    "stages = [f'Stage {i+1}' for i in range(len(stage_info['samples_per_stage']))]\n",
    "samples = stage_info['samples_per_stage']\n",
    "rejections = stage_info['rejections_per_stage']\n",
    "\n",
    "axes[0].bar(stages, samples, alpha=0.7, label='Samples evaluated', color='blue')\n",
    "axes[0].bar(stages, rejections, alpha=0.7, label='Samples rejected', color='red')\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[0].set_title('Cascade Stage Processing', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Rejection rates\n",
    "rejection_rates = [r/s if s > 0 else 0 for r, s in zip(rejections, samples)]\n",
    "axes[1].bar(stages, rejection_rates, alpha=0.7, color='orange')\n",
    "axes[1].set_ylabel('Rejection Rate', fontsize=12)\n",
    "axes[1].set_title('Rejection Rate per Stage', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add percentage labels\n",
    "for i, (stage, rate) in enumerate(zip(stages, rejection_rates)):\n",
    "    axes[1].text(i, rate + 0.02, f'{rate:.1%}', ha='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/cascade_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CASCADE V1 RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Configuration:\n",
      "  Stages: 2\n",
      "  Total weak classifiers: 50\n",
      "    Stage 1: 10 weak classifiers, threshold=0.3068\n",
      "    Stage 2: 40 weak classifiers, threshold=0.4406\n",
      "\n",
      "Test Performance:\n",
      "  Accuracy:  74.92%\n",
      "  Precision: 39.04%\n",
      "  Recall:    89.91%\n",
      "  F1 Score:  54.44%\n",
      "\n",
      "Computational Efficiency:\n",
      "  Stage 1: 100.0% of samples evaluated\n",
      "  Stage 2: 64.7% of samples evaluated\n",
      "\n",
      "============================================================\n",
      "[OK] V1 Complete! Cascade achieves >70% accuracy\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CASCADE V1 RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Stages: {len(cascade.stages)}\")\n",
    "print(f\"  Total weak classifiers: {sum(len(s.classifier.weak_classifiers) for s in cascade.stages)}\")\n",
    "for i, stage in enumerate(cascade.stages, 1):\n",
    "    print(f\"    Stage {i}: {len(stage.classifier.weak_classifiers)} weak classifiers, threshold={stage.threshold:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  Accuracy:  {test_metrics['accuracy']:.2%}\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.2%}\")\n",
    "print(f\"  Recall:    {test_metrics['recall']:.2%}\")\n",
    "print(f\"  F1 Score:  {test_metrics['f1']:.2%}\")\n",
    "\n",
    "print(f\"\\nComputational Efficiency:\")\n",
    "total_samples = stage_info['samples_per_stage'][0]\n",
    "for i, n_samples in enumerate(stage_info['samples_per_stage'], 1):\n",
    "    pct = n_samples / total_samples if total_samples > 0 else 0\n",
    "    print(f\"  Stage {i}: {pct:.1%} of samples evaluated\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if test_metrics['accuracy'] >= 0.70:\n",
    "    print(\"[OK] V1 Complete! Cascade achieves >70% accuracy\")\n",
    "else:\n",
    "    print(\"Note: Consider tuning thresholds or adding more stages\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **V1 Milestone**: If accuracy >70%, Part 1 implementation complete!\n",
    "2. **V2 Scale-up**: Increase to 50k features, T=200, more cascade stages\n",
    "3. **Part 2**: Implement sliding window detection on full images\n",
    "4. **Report**: Document algorithm, results, and analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ell715-assignment-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
