{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Training for Viola-Jones Face Detector\\n",
    "\\n",
    "Train 2-stage cascade classifier to reduce false positives.\\n",
    "\\n",
    "**V1 Configuration**:\\n",
    "- Stage 1: T=10 (reject ~50% non-faces, keep >99% faces)\\n",
    "- Stage 2: T=40 (final discriminative stage)\\n",
    "- Combined: High detection rate with low FP rate\\n",
    "\\n",
    "**AI Usage**: Notebook structure assisted by Claude Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\\n",
    "import matplotlib.pyplot as plt\\n",
    "import pickle\\n",
    "import sys\\n",
    "from pathlib import Path\\n",
    "\\n",
    "# Add src to path\\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\\n",
    "\\n",
    "from classifiers.cascade import train_cascade, evaluate_cascade, CascadeClassifier\\n",
    "from features.haar_features import generate_haar_features\\n",
    "\\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pre-computed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset labels...\")\\n",
    "\\n",
    "# Load training data\\n",
    "with open('../data/processed/train_faces.pkl', 'rb') as f:\\n",
    "    train_faces = pickle.load(f)\\n",
    "\\n",
    "with open('../data/processed/train_nonfaces.pkl', 'rb') as f:\\n",
    "    train_nonfaces = pickle.load(f)\\n",
    "\\n",
    "# Create labels\\n",
    "y_train = np.concatenate([\\n",
    "    np.ones(len(train_faces), dtype=int),\\n",
    "    np.zeros(len(train_nonfaces), dtype=int)\\n",
    "])\\n",
    "\\n",
    "# Load testing data\\n",
    "with open('../data/processed/test_faces.pkl', 'rb') as f:\\n",
    "    test_faces = pickle.load(f)\\n",
    "\\n",
    "with open('../data/processed/test_nonfaces.pkl', 'rb') as f:\\n",
    "    test_nonfaces = pickle.load(f)\\n",
    "\\n",
    "y_test = np.concatenate([\\n",
    "    np.ones(len(test_faces), dtype=int),\\n",
    "    np.zeros(len(test_nonfaces), dtype=int)\\n",
    "])\\n",
    "\\n",
    "print(f\"Training: {len(train_faces)} faces, {len(train_nonfaces)} non-faces\")\\n",
    "print(f\"Testing: {len(test_faces)} faces, {len(test_nonfaces)} non-faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed feature responses\\n",
    "print(\"\\nLoading pre-computed feature responses...\")\\n",
    "train_responses = np.load('../data/processed/train_responses_10k.npy')\\n",
    "test_responses = np.load('../data/processed/test_responses_10k.npy')\\n",
    "\\n",
    "print(f\"Training responses: {train_responses.shape}\")\\n",
    "print(f\"Testing responses: {test_responses.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\\n",
    "print(\"\\nGenerating Haar features (same as training)...\")\\n",
    "features = generate_haar_features(window_size=16, max_features=10000)\\n",
    "print(f\"Generated {len(features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Cascade Configuration\\n",
    "\\n",
    "**2-Stage Cascade**:\\n",
    "- Stage 1: Fast filter (T=10, high recall)\\n",
    "- Stage 2: Discriminative (T=40, balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_configs = [\\n",
    "    {\\n",
    "        'T': 10,\\n",
    "        'target_fpr': 0.5,    # Reject 50% of non-faces\\n",
    "        'target_tpr': 0.995   # Keep 99.5% of faces\\n",
    "    },\\n",
    "    {\\n",
    "        'T': 40,\\n",
    "        'target_fpr': 0.01,   # Very low FP rate for final stage\\n",
    "        'target_tpr': 0.99    # 99% face detection\\n",
    "    }\\n",
    "]\\n",
    "\\n",
    "print(\"Cascade Configuration:\")\\n",
    "for i, config in enumerate(stage_configs, 1):\\n",
    "    print(f\"  Stage {i}: T={config['T']}, FPR={config['target_fpr']:.1%}, TPR={config['target_tpr']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Cascade\\n",
    "\\n",
    "**This will take several minutes**\\n",
    "- Stage 1: Train on full dataset\\n",
    "- Stage 2: Train on faces + FPs from Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = train_cascade(\\n",
    "    train_responses,\\n",
    "    y_train,\\n",
    "    features,\\n",
    "    stage_configs,\\n",
    "    verbose=True\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating cascade on TRAINING set...\")\\n",
    "train_metrics = evaluate_cascade(cascade, train_responses, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating cascade on TEST set...\")\\n",
    "test_metrics = evaluate_cascade(cascade, test_responses, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Cascade Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('../data/models/cascade_v1_2stage.pkl')\\n",
    "cascade.save(model_path)\\n",
    "print(f\"\\nCascade saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare with Single AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single AdaBoost model if it exists\\n",
    "from classifiers.adaboost import AdaBoostClassifier, evaluate_classifier\\n",
    "\\n",
    "adaboost_path = Path('../data/models/adaboost_v1_T50.pkl')\\n",
    "if adaboost_path.exists():\\n",
    "    print(\"Loading single AdaBoost model for comparison...\")\\n",
    "    adaboost = AdaBoostClassifier.load(adaboost_path)\\n",
    "    \\n",
    "    print(\"\\nSingle AdaBoost (T=50) on TEST set:\")\\n",
    "    adaboost_metrics = evaluate_classifier(adaboost, test_responses, y_test, verbose=True)\\n",
    "    \\n",
    "    # Comparison table\\n",
    "    print(\"\\n\" + \"=\" * 60)\\n",
    "    print(\"COMPARISON: Cascade vs Single AdaBoost\")\\n",
    "    print(\"=\" * 60)\\n",
    "    print(f\"{'Metric':<15} {'Cascade':<15} {'AdaBoost T=50':<15}\")\\n",
    "    print(\"-\" * 60)\\n",
    "    print(f\"{'Accuracy':<15} {test_metrics['accuracy']:<15.2%} {adaboost_metrics['accuracy']:<15.2%}\")\\n",
    "    print(f\"{'Precision':<15} {test_metrics['precision']:<15.2%} {adaboost_metrics['precision']:<15.2%}\")\\n",
    "    print(f\"{'Recall':<15} {test_metrics['recall']:<15.2%} {adaboost_metrics['recall']:<15.2%}\")\\n",
    "    print(f\"{'F1 Score':<15} {test_metrics['f1']:<15.2%} {adaboost_metrics['f1']:<15.2%}\")\\n",
    "    print(\"=\" * 60)\\n",
    "else:\\n",
    "    print(\"Single AdaBoost model not found. Train it first using 03_adaboost_training.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Cascade Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage-by-stage rejection rates\\n",
    "stage_info = test_metrics['stage_info']\\n",
    "\\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n",
    "\\n",
    "# Bar plot: samples per stage\\n",
    "stages = [f'Stage {i+1}' for i in range(len(stage_info['samples_per_stage']))]\\n",
    "samples = stage_info['samples_per_stage']\\n",
    "rejections = stage_info['rejections_per_stage']\\n",
    "\\n",
    "axes[0].bar(stages, samples, alpha=0.7, label='Samples evaluated', color='blue')\\n",
    "axes[0].bar(stages, rejections, alpha=0.7, label='Samples rejected', color='red')\\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=12)\\n",
    "axes[0].set_title('Cascade Stage Processing', fontsize=13, fontweight='bold')\\n",
    "axes[0].legend()\\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\\n",
    "\\n",
    "# Rejection rates\\n",
    "rejection_rates = [r/s if s > 0 else 0 for r, s in zip(rejections, samples)]\\n",
    "axes[1].bar(stages, rejection_rates, alpha=0.7, color='orange')\\n",
    "axes[1].set_ylabel('Rejection Rate', fontsize=12)\\n",
    "axes[1].set_title('Rejection Rate per Stage', fontsize=13, fontweight='bold')\\n",
    "axes[1].set_ylim([0, 1])\\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\\n",
    "\\n",
    "# Add percentage labels\\n",
    "for i, (stage, rate) in enumerate(zip(stages, rejection_rates)):\\n",
    "    axes[1].text(i, rate + 0.02, f'{rate:.1%}', ha='center', fontsize=11)\\n",
    "\\n",
    "plt.tight_layout()\\n",
    "plt.savefig('../results/figures/cascade_performance.png', dpi=150, bbox_inches='tight')\\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\\n",
    "print(\"CASCADE V1 RESULTS SUMMARY\")\\n",
    "print(\"=\" * 60)\\n",
    "print(f\"\\nConfiguration:\")\\n",
    "print(f\"  Stages: {len(cascade.stages)}\")\\n",
    "print(f\"  Total weak classifiers: {sum(len(s.classifier.weak_classifiers) for s in cascade.stages)}\")\\n",
    "for i, stage in enumerate(cascade.stages, 1):\\n",
    "    print(f\"    Stage {i}: {len(stage.classifier.weak_classifiers)} weak classifiers, threshold={stage.threshold:.4f}\")\\n",
    "\\n",
    "print(f\"\\nTest Performance:\")\\n",
    "print(f\"  Accuracy:  {test_metrics['accuracy']:.2%}\")\\n",
    "print(f\"  Precision: {test_metrics['precision']:.2%}\")\\n",
    "print(f\"  Recall:    {test_metrics['recall']:.2%}\")\\n",
    "print(f\"  F1 Score:  {test_metrics['f1']:.2%}\")\\n",
    "\\n",
    "print(f\"\\nComputational Efficiency:\")\\n",
    "total_samples = stage_info['samples_per_stage'][0]\\n",
    "for i, n_samples in enumerate(stage_info['samples_per_stage'], 1):\\n",
    "    pct = n_samples / total_samples if total_samples > 0 else 0\\n",
    "    print(f\"  Stage {i}: {pct:.1%} of samples evaluated\")\\n",
    "\\n",
    "print(\"\\n\" + \"=\" * 60)\\n",
    "if test_metrics['accuracy'] >= 0.70:\\n",
    "    print(\"[OK] V1 Complete! Cascade achieves >70% accuracy\")\\n",
    "else:\\n",
    "    print(\"Note: Consider tuning thresholds or adding more stages\")\\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\\n",
    "\\n",
    "1. **V1 Milestone**: If accuracy >70%, Part 1 implementation complete!\\n",
    "2. **V2 Scale-up**: Increase to 50k features, T=200, more cascade stages\\n",
    "3. **Part 2**: Implement sliding window detection on full images\\n",
    "4. **Report**: Document algorithm, results, and analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
